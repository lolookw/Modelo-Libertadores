# Proyecto 2 ‚Äî Predicci√≥n 1X2 en Copa Libertadores (1996‚Äì2024)

Este repo es el **Proyecto 2** de mi portfolio (8 semanas, 4‚Äì6 proyectos). El objetivo fue construir un pipeline **publicable y reproducible** de **modelado + evaluaci√≥n + storytelling**, usando como base el dataset armado en el **Proyecto 1** (Libertadores 1996‚Äì2024).

La idea del proyecto es mostrar un proceso realista de trabajo:
- definir un problema de predicci√≥n
- evitar leakage (muy com√∫n en deportes)
- establecer baselines fuertes
- mejorar incrementalmente
- evaluar con m√©tricas correctas (no solo accuracy)
- documentar aprendizajes (incluyendo experimentos que no mejoran)

---

## Problema de predicci√≥n (1X2)

**Tarea:** predecir el resultado de un partido:
- `L` = gana el local
- `E` = empate
- `V` = gana el visitante

**Restricci√≥n clave:** usar **solo informaci√≥n disponible antes del partido** (pre-partido).  
Nada de features que ‚Äúmiran‚Äù el resultado del partido o estad√≠sticas posteriores.

---

## Datos

**Fuente base:** dataset procesado del Proyecto 1.

Archivo de entrada (local, fuera de este repo):
- `C:\Users\Lorenzo\Desktop\coding\Libertadores-1996-2024\datos\procesados\partidos_rsssf1_enriquecido.csv`

Columnas relevantes (ejemplo):
- `fecha_parseada`, `temporada`, `fase`, `equipo_local`, `equipo_visitante`, `pais_local`, `pais_visitante`
- `goles_local`, `goles_visitante`, `resultado_norm`
- `pais_sede` (para neutralidad / finales)

**Dataset final ‚Äúmodel-ready‚Äù (generado en este repo):**
- `data/processed/partidos_modelo_1x2.csv`
- 3,149 partidos (1996-03-13 ‚Üí 2024-06-04)

Distribuci√≥n global aproximada:
- `L`: ~55%
- `E`: ~23%
- `V`: ~22%

---

## Split temporal (anti-leakage)

Para simular un uso real (predicci√≥n futura), el split es **por tiempo**:

- **Train:** hist√≥rico (mayor parte del per√≠odo)
- **Validation:** a√±os recientes intermedios (para decisiones de modelo)
- **Test:** a√±os m√°s recientes (evaluaci√≥n final)

> Nota: el split exacto se implementa en `src/preparacion_datos.py` y queda guardado en la columna `split`. Lo importante es que el test representa ‚Äúfuturo‚Äù respecto a train/val.

---

## M√©tricas

La m√©trica principal elegida fue **Logloss (cross-entropy)**, porque el deliverable final son **probabilidades** (√∫tiles para ranking/decisiones), no solo un ‚Äúacierto/no acierto‚Äù.

Adem√°s se reportan:
- Accuracy
- Balanced Accuracy (importante por desbalance de clases)
- Macro F1
- Matriz de confusi√≥n (para entender errores t√≠picos)

---

# Enfoque y evoluci√≥n del modelo (la historia del proyecto)

## Paso 1 ‚Äî Baselines simples (pisos)

Arranqu√© con baselines deliberadamente simples para tener un ‚Äúpiso‚Äù:

### Baseline 1: ‚ÄúSiempre Local‚Äù
Predice `L` para todo.
- Sirve para cuantificar cu√°nto explica solo la local√≠a y el desbalance.
- Da una accuracy alrededor de ~0.50‚Äì0.52, pero m√©tricas por clase muy flojas.
- Logloss alto (probabilidades malas / demasiado seguras).

### Baseline 2: ‚ÄúFrecuencias por fase‚Äù
Estima probabilidades por `fase` usando train y las aplica a val/test.
- Mejora fuerte logloss vs ‚Äúsiempre local‚Äù (porque ya produce probabilidades razonables).
- Pero sigue tendiendo a predecir `L` como argmax, y no capta fuerza relativa de equipos.

**Aprendizaje:** hace falta una se√±al de ‚Äúfuerza‚Äù / calidad relativa para separar `L` de `V` de forma consistente.

---

## Paso 2 ‚Äî Baseline fuerte: Elo pre-partido (sin leakage)

Implement√© un baseline **Elo** porque:
- es el est√°ndar m√≠nimo serio para fuerza relativa en deportes
- es **pre-partido** por construcci√≥n (si se calcula bien)
- es interpretable y f√°cil de explicar

### Elo (Baseline 3)
- Cada equipo arranca con Elo=1500
- Se recorre train **en orden temporal**
- Para cada partido se predice con Elo pre-partido y luego se actualiza Elo con el resultado real
- En val/test se predice usando Elo aprendido en train (sin actualizar)

#### Neutralidad (finales / sede)
Como en copas hay partidos ‚Äúneutrales‚Äù (ej. Final o sede distinta), se incorpora una regla:
- si el partido es neutral ‚áí ventaja_local = 0
- caso normal ‚áí ventaja_local > 0

#### Empates en Elo
Un Elo binario cl√°sico no modela empates naturalmente. Se prob√≥ un esquema simple para repartir probabilidad de empate en funci√≥n de la ‚Äúparejidad‚Äù (dif Elo cerca de 0 ‚áí m√°s empate). Aun as√≠, el empate es una clase dif√≠cil y suele no ganar como argmax.

**Resultado:** Elo mejora claramente vs baselines simples y se convierte en un baseline competitivo.

**Aprendizaje:** Elo es una gran base, pero:
- no captura ‚Äúforma reciente‚Äù expl√≠cita
- y predecir empates como clase hard sigue siendo dif√≠cil

---

## Paso 3 ‚Äî Primer modelo ML: ‚Äúforma + fase‚Äù (y por qu√© NO alcanz√≥)

Se generaron features rolling pre-partido (ventana N=5) por equipo:

- puntos promedio √∫ltimos N
- GF promedio √∫ltimos N
- GC promedio √∫ltimos N  
para local y visitante (incluye partidos home+away, con `shift(1)` para evitar leakage)

Adem√°s:
- `neutral`
- one-hot de `fase`

Se entren√≥ una **Regresi√≥n Log√≠stica multinomial** (pipeline con imputaci√≥n y escalado).

**Resultado:** este modelo fue flojo: tend√≠a a predecir `L` casi siempre y no super√≥ a Elo.

**Aprendizaje clave:** la ‚Äúforma‚Äù sola es ruidosa. Falta la se√±al base de fuerza global.

---

## Paso 4 ‚Äî Modelo ML ganador: Log√≠stica + Elo + forma (pre-partido)

El salto real fue incluir Elo como feature (pre-partido), junto con forma y fase:

Features num√©ricas principales:
- `dif_elo`, `elo_local`, `elo_visitante`
- `neutral`
- rollings (puntos/GF/GC local y visitante)

Feature categ√≥rica:
- `fase` (one-hot)

**Resultado:** mejora clara respecto a Elo baseline y a ML sin Elo.  
En test, el modelo logra aproximadamente:
- **logloss ~0.97**
- **accuracy ~0.55**

**Interpretaci√≥n:** el modelo combina:
- fuerza relativa estructural (Elo)
- se√±ales recientes (forma rolling)
- contexto competitivo (fase)
- y ajusta probabilidades con un modelo simple e interpretable

---

## Paso 5 ‚Äî Ablation: ‚Äúdif_forma‚Äù (experimento que NO mejor√≥)

Se prob√≥ agregar features diferenciales:
- `dif_puntos_ultN`, `dif_gf_ultN`, `dif_gc_ultN`

**Resultado:** m√©tricas pr√°cticamente id√©nticas.  
**Conclusi√≥n:** esa se√±al ya estaba capturada por `dif_elo` y/o rollings individuales.

Esto se documenta como parte del proceso: no todo ‚Äúfeature engineering razonable‚Äù mejora.

---

## Paso 6 ‚Äî Calibraci√≥n: Temperature Scaling (mejora final en logloss)

Como el objetivo incluye probabilidades √∫tiles, se aplic√≥ **temperature scaling**:

- se aprende `T` **solo en validaci√≥n**
- se eval√∫a el impacto en test sin tocar el split

Resultado:
- `T ‚âà 1.10` (modelo ligeramente sobreconfiado)
- logloss baja un poco en val y test
- accuracy y matrices casi no cambian (esperable)

**Modelo final recomendado:** ML + Elo + forma + fase + neutralidad **calibrado**.

---

## Estructura del repo

- `data/`
  - `processed/` (datasets generados para modelado)
- `src/`
  - `preparacion_datos.py` ‚Üí crea `partidos_modelo_1x2.csv` con split temporal
  - `features_prepartido.py` ‚Üí features rolling pre-partido
  - `features_elo.py` ‚Üí Elo pre-partido como features (sin leakage)
  - `entrenamiento.py` ‚Üí entrena regresi√≥n log√≠stica (pipeline reproducible)
  - `evaluacion.py` ‚Üí baselines
  - `evaluacion_modelo.py` ‚Üí eval√∫a modelo ML
  - `calibracion_temperature.py` ‚Üí calibraci√≥n por temperature scaling
  - `reporte_consolidado.py` ‚Üí genera reporte final
- `informes/`
  - reportes `.md` con resultados
- `modelos/`
  - `.joblib` del modelo y par√°metros de calibraci√≥n

---

## C√≥mo reproducir (pipeline)

> Asume Python 3.11 en Windows y entorno virtual activo.

1) Generar dataset model-ready:
```powershell
python .\src\preparacion_datos.py --ruta_entrada "C:\Users\Lorenzo\Desktop\coding\Libertadores-1996-2024\datos\procesados\partidos_rsssf1_enriquecido.csv"
```
2) Baselines:
```powershell
python .\src\evaluacion.py
```

3) Features rolling:
```powershell
python .\src\features_prepartido.py --ventana 5
```

4) Features Elo:
```powershell
python .\src\features_elo.py
```

5) Entrenar modelo (ejemplo):
```powershell
python .\src\entrenamiento.py --ruta_features .\data\processed\partidos_features_ml_con_elo.csv --ruta_modelo_salida modelos\modelo_logistico_1x2_final.joblib
```

6) Evaluar modelo:
```powershell
python .\src\evaluacion_modelo.py --ruta_features .\data\processed\partidos_features_ml_con_elo.csv --ruta_modelo modelos\modelo_logistico_1x2_final.joblib --ruta_reporte informes\reporte_modelo_final.md
```

7) Calibraci√≥n (temperature scaling):
```powershell
python .\src\calibracion_temperature.py --ruta_features .\data\processed\partidos_features_ml_con_elo.csv --ruta_modelo modelos\modelo_logistico_1x2_final.joblib
```

8) Reporte consolidado:
```powershell
python .\src\reporte_consolidado.py --ruta_ml_con_elo informes\reporte_modelo_final.md --ruta_salida informes\reporte_final.md
```

## üß† Principales Aprendizajes

* **El impacto del Baseline:** Un baseline "serio" basado en **Elo** cambia completamente el juego; entender la fuerza relativa de los equipos es un factor cr√≠tico para el √©xito del modelo.
* **Insuficiencia de la "forma":** La m√©trica de *forma rolling* por s√≠ sola no alcanza; es excesivamente ruidosa y el modelo tiende a colapsar simplificando todo a la local√≠a.
* **Sinergia de Features:** Agregar **Elo como feature** y entrenar un modelo simple (como Regresi√≥n Log√≠stica) produce mejoras reales, consistentes y reproducibles.
* **Calibraci√≥n de Probabilidades:** La calibraci√≥n representa una mejora sustancial en la "calidad probabil√≠stica" (**logloss**), independientemente de si el *accuracy* se mantiene estable.
* **El desaf√≠o del empate:** Los empates siguen siendo una "clase hard" muy dif√≠cil de predecir; es el punto de fricci√≥n m√°s claro para el desarrollo futuro.

---

## üöÄ Limitaciones y Pr√≥ximos Pasos

### ‚öñÔ∏è Gesti√≥n de Empates
El modelo actual rara vez predice el empate como la opci√≥n m√°s probable (*argmax*). Para mitigar esto, se planea:
* Implementar **modelos no lineales** m√°s robustos como `HistGradientBoosting` o `XGBoost`.
* Dise√±ar **features espec√≠ficas de empate** (paridad extrema de fuerzas, contextos de eliminaci√≥n directa, etc.).

### ‚è≥ Generalizaci√≥n por √âpocas
La Copa Libertadores ha evolucionado significativamente en formato y nivel competitivo. Las estrategias a probar incluyen:
* Aplicar t√©cnicas de **rolling por ventanas de tiempo** espec√≠ficas.
* Crear **features por era/torneo** para capturar la din√°mica de cada √©poca del f√∫tbol sudamericano.

